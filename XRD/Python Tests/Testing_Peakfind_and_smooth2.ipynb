{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8352362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dilan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\linalg\\_dsolve\\linsolve.py:293: MatrixRankWarning: Matrix is exactly singular\n",
      "  warn(\"Matrix is exactly singular\", MatrixRankWarning)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'region_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30864\\555320441.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;36m45.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m47.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;36m50.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m52.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;36m55.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m57.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     ]\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mprocess_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFOLDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mREGIONS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30864\\555320441.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(folder, regions, smoothing, baseline, min_prominence, max_peaks_per_region, output_dir)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Skipping {os.path.basename(f)}: {e}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         df = analyze_peaks_in_regions(\n\u001b[0m\u001b[0;32m    221\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mmin_prominence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_prominence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mmax_peaks_per_region\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_peaks_per_region\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30864\\555320441.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, regions, smoothing, baseline, min_prominence, max_peaks_per_region)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[1;34m'area_under_peak'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marea\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;34m'prominence'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prominences'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             })\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'region_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'peak_x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6923\u001b[0m                 \u001b[1;34mf\"Length of ascending ({len(ascending)})\"\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6924\u001b[0m                 \u001b[1;34mf\" != length of by ({len(by)})\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6925\u001b[0m             )\n\u001b[0;32m   6926\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6927\u001b[1;33m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6929\u001b[0m             \u001b[1;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6930\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m-> 6927\u001b[1;33m         \u001b[1;33m...\u001b[0m     \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_natsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"time\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1844\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'region_id'"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.signal import savgol_filter, find_peaks, peak_widths\n",
    "from scipy import integrate\n",
    "from scipy.sparse import diags, eye as sp_eye\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "# ===== Baselines =====\n",
    "def _poly_baseline(x, y, deg=3):\n",
    "    if len(x) < deg + 1:\n",
    "        return np.zeros_like(y)\n",
    "    mask = np.ones_like(y, dtype=bool)\n",
    "    for _ in range(3):\n",
    "        coeffs = np.polyfit(x[mask], y[mask], deg)\n",
    "        base = np.polyval(coeffs, x)\n",
    "        mask = y <= base\n",
    "    return np.polyval(np.polyfit(x, y, deg), x)\n",
    "\n",
    "def _als_baseline_sparse(y, lam=1e6, p=0.01, niter=10):\n",
    "    \"\"\"Asymmetric least squares baseline (sparse, robust for long signals).\"\"\"\n",
    "    L = len(y)\n",
    "    if L < 3:\n",
    "        return np.zeros_like(y)\n",
    "    # second-difference operator (L-2 by L) as sparse:\n",
    "    D = diags([1, -2, 1], [0, -1, -2], shape=(L-2, L))\n",
    "    w = np.ones(L)\n",
    "    for _ in range(niter):\n",
    "        W = diags(w, 0, shape=(L, L))\n",
    "        Z = W + lam * (D.T @ D)\n",
    "        b = spsolve(Z, w * y)\n",
    "        w = p * (y > b) + (1 - p) * (y < b)\n",
    "    return b\n",
    "\n",
    "def integrate_region(x, y, xlo, xhi):\n",
    "    m = (x >= xlo) & (x <= xhi)\n",
    "    if np.count_nonzero(m) < 2:\n",
    "        return 0.0\n",
    "    return integrate.trapezoid(y[m], x[m])\n",
    "\n",
    "# ===== Core analysis =====\n",
    "def analyze_peaks_in_regions(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    regions: List[Tuple[float, float]],\n",
    "    smoothing: Optional[Dict] = None,\n",
    "    baseline: Dict = None,\n",
    "    min_prominence: float = None,\n",
    "    max_peaks_per_region: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    if smoothing is None:\n",
    "        smoothing = {'method':'savgol', 'window':15, 'polyorder':3}\n",
    "    if baseline is None:\n",
    "        baseline = {'method':'als', 'lam':1e6, 'p':0.01}\n",
    "\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "\n",
    "    # light smoothing (guard window length)\n",
    "    if smoothing.get('method','savgol') == 'savgol':\n",
    "        w = int(smoothing.get('window', 15))\n",
    "        p = int(smoothing.get('polyorder', 3))\n",
    "        w = max(5, w + (w % 2 == 0))  # odd, >=5\n",
    "        # If global data are short, clamp window\n",
    "        w = min(w, (len(x)//2)*2 - 1) if len(x) > 7 else 5\n",
    "        y_s = savgol_filter(y, window_length=max(5, w), polyorder=min(p, 3), mode='interp')\n",
    "    else:\n",
    "        y_s = y.copy()\n",
    "\n",
    "    out = []\n",
    "    for r_id, (xlo, xhi) in enumerate(regions, start=1):\n",
    "        m = (x >= xlo) & (x <= xhi)\n",
    "        if np.count_nonzero(m) < 7:   # need a few points for widths\n",
    "            continue\n",
    "\n",
    "        xr = x[m]\n",
    "        yr = y_s[m]\n",
    "\n",
    "        # choose baseline per region\n",
    "        bmethod = baseline.get('method','als')\n",
    "        if bmethod == 'als':\n",
    "            b = _als_baseline_sparse(yr, lam=baseline.get('lam', 1e6), p=baseline.get('p', 0.01))\n",
    "        elif bmethod == 'poly':\n",
    "            b = _poly_baseline(xr, yr, deg=baseline.get('deg', 3))\n",
    "        else:\n",
    "            b = np.zeros_like(yr)\n",
    "\n",
    "        yr_corr = yr - b\n",
    "\n",
    "        # auto-prominence if not provided\n",
    "        prom = min_prominence\n",
    "        if prom is None:\n",
    "            mad = np.median(np.abs(yr_corr - np.median(yr_corr)))\n",
    "            noise = 1.4826 * mad\n",
    "            prom = max(noise * 5, (yr_corr.max() - yr_corr.min()) * 0.02)\n",
    "\n",
    "        pks, props = find_peaks(yr_corr, prominence=prom)\n",
    "        if pks.size == 0:\n",
    "            continue\n",
    "\n",
    "        # FWHM in sample-index units\n",
    "        widths, w_left, w_right, _ = peak_widths(yr_corr, pks, rel_height=0.5)\n",
    "\n",
    "        # Convert index positions to x by interpolation\n",
    "        idx_axis = np.arange(len(xr), dtype=float)\n",
    "        left_x = np.interp(w_left, idx_axis, xr)\n",
    "        right_x = np.interp(w_right, idx_axis, xr)\n",
    "\n",
    "        # FWHM in x-units\n",
    "        fwhm_x = right_x - left_x\n",
    "\n",
    "        # keep strongest peaks per region\n",
    "        order = np.argsort(props['prominences'])[::-1][:max_peaks_per_region]\n",
    "\n",
    "        for idx in order:\n",
    "            i = pks[idx]\n",
    "            peak_x = xr[i]\n",
    "            # we'll write peak_y in raw coordinates (not baseline-corrected) later in process_folder\n",
    "            height = yr_corr[i]  # above baseline\n",
    "            area = integrate_region(xr, yr_corr, left_x[idx], right_x[idx])\n",
    "\n",
    "            out.append({\n",
    "                'region_id': r_id,\n",
    "                'x_lo': xlo, 'x_hi': xhi,\n",
    "                'peak_x': float(peak_x),\n",
    "                'peak_y': float(yr[i]),            # smoothed signal at summit (temporary)\n",
    "                'baseline_at_peak': float(b[i]),\n",
    "                'height': float(height),\n",
    "                'fwhm_x': float(fwhm_x[idx]),\n",
    "                'left_ips_x': float(left_x[idx]),\n",
    "                'right_ips_x': float(right_x[idx]),\n",
    "                'area_under_peak': float(area),\n",
    "                'prominence': float(props['prominences'][idx]),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(out).sort_values(['region_id', 'peak_x']).reset_index(drop=True)\n",
    "\n",
    "# ===== I/O + plotting =====\n",
    "def load_xy(path):\n",
    "    \"\"\"Robustly read 2-column .xy with whitespace, comma, or semicolon.\"\"\"\n",
    "    try:\n",
    "        data = np.loadtxt(path)\n",
    "    except Exception:\n",
    "        data = np.loadtxt(path, delimiter=',')\n",
    "    if data.ndim != 2 or data.shape[1] < 2:\n",
    "        raise ValueError(f\"File {path} is not a 2-column XY.\")\n",
    "    return data[:,0], data[:,1]\n",
    "\n",
    "def format_table_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return pd.DataFrame({'info': ['No peaks found in regions.']})\n",
    "    view = df[['region_id','peak_x','height','fwhm_x','area_under_peak']].copy()\n",
    "    return (view\n",
    "            .rename(columns={'region_id':'Reg','peak_x':'Position','height':'Height',\n",
    "                             'fwhm_x':'FWHM','area_under_peak':'Area'})\n",
    "            .astype({'Reg':int})\n",
    "            .round({'Position':4, 'Height':2, 'FWHM':4, 'Area':2})\n",
    "           )\n",
    "\n",
    "def plot_trace_with_table(x, y, peaks_df, title=None, out_png=None):\n",
    "    fig = plt.figure(figsize=(10, 6.5))\n",
    "    gs = GridSpec(3, 1, height_ratios=[2.0, 0.05, 1.0])\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    ax.plot(x, y, lw=1)\n",
    "    ax.set_xlabel(r'$2\\theta$')\n",
    "    ax.set_ylabel('Intensity (a.u.)')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    if not peaks_df.empty:\n",
    "        ax.scatter(peaks_df['peak_x'], peaks_df['peak_y_raw'], s=35, marker='x')\n",
    "        for _, r in peaks_df.iterrows():\n",
    "            ax.annotate(f\"{r['peak_x']:.3f}\",\n",
    "                        xy=(r['peak_x'], r['peak_y_raw']),\n",
    "                        xytext=(0, 6), textcoords='offset points',\n",
    "                        ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    ax_tbl = fig.add_subplot(gs[2, 0])\n",
    "    ax_tbl.axis('off')\n",
    "    tbl_df = format_table_df(peaks_df)\n",
    "    table = ax_tbl.table(cellText=tbl_df.values,\n",
    "                         colLabels=tbl_df.columns.tolist(),\n",
    "                         loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 1.2)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if out_png:\n",
    "        fig.savefig(out_png, dpi=200, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "def process_folder(\n",
    "    folder: str,\n",
    "    regions: List[Tuple[float, float]],\n",
    "    smoothing={'method':'savgol','window':21,'polyorder':3},\n",
    "    baseline={'method':'als','lam':1e5,'p':0.01},\n",
    "    min_prominence=None,\n",
    "    max_peaks_per_region=2,\n",
    "    output_dir='peak_reports'\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    files = sorted(glob.glob(os.path.join(folder, \"*.xy\")))\n",
    "    if not files:\n",
    "        print(\"No .xy files found.\")\n",
    "        return\n",
    "\n",
    "    all_rows = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            x, y = load_xy(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {os.path.basename(f)}: {e}\")\n",
    "            continue\n",
    "\n",
    "        df = analyze_peaks_in_regions(\n",
    "            x, y, regions, smoothing, baseline,\n",
    "            min_prominence=min_prominence,\n",
    "            max_peaks_per_region=max_peaks_per_region\n",
    "        )\n",
    "\n",
    "        if not df.empty:\n",
    "            # Replace temporary peak_y with RAW y at nearest index (prettier on plot)\n",
    "            idxs = np.searchsorted(x, df['peak_x'].values)\n",
    "            idxs = np.clip(idxs, 0, len(x)-1)\n",
    "            df['peak_y_raw'] = y[idxs]\n",
    "            # keep smoothed value too if you like:\n",
    "            # df.rename(columns={'peak_y':'peak_y_smoothed'}, inplace=True)\n",
    "            df.insert(0, 'file', os.path.splitext(os.path.basename(f))[0])\n",
    "\n",
    "        base = os.path.splitext(os.path.basename(f))[0]\n",
    "        out_png = os.path.join(output_dir, f\"{base}_peaks.png\")\n",
    "        plot_trace_with_table(x, y, df if not df.empty else pd.DataFrame(), title=base, out_png=out_png)\n",
    "\n",
    "        if not df.empty:\n",
    "            all_rows.append(df)\n",
    "\n",
    "    if all_rows:\n",
    "        summary = pd.concat(all_rows, ignore_index=True)\n",
    "        summary.to_csv(os.path.join(output_dir, \"peak_summary.csv\"), index=False)\n",
    "        print(f\"Saved figures + summary CSV in: {os.path.abspath(output_dir)}\")\n",
    "    else:\n",
    "        print(\"No peaks were found in the specified regions for any file.\")\n",
    "\n",
    "# ===== Example run (edit paths/regions) =====\n",
    "if __name__ == \"__main__\":\n",
    "    FOLDER = r\"C:\\\\Dilan\\\\Study\\\\Master Thesis\\\\Characterization\\\\XRD\\\\30-09-2025 Dep No 1\\\\XY Data\"\n",
    "    REGIONS = [\n",
    "        (20.5, 23.0),\n",
    "        (30.5, 33.0),\n",
    "        (37.5, 40.0),\n",
    "        (45.0, 47.5),\n",
    "        (50.0, 52.5),\n",
    "        (55.0, 57.5),\n",
    "    ]\n",
    "    process_folder(FOLDER, REGIONS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
